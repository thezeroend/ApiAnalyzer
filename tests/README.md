# ðŸ§ª Scripts de Teste - API Log Analyzer

Esta pasta contÃ©m todos os scripts de teste para validar e demonstrar as funcionalidades do sistema de anÃ¡lise de anomalias em logs de API.

## ðŸ“‹ Ãndice

- [Scripts BÃ¡sicos](#scripts-bÃ¡sicos)
- [Scripts de Machine Learning](#scripts-de-machine-learning)
- [Scripts de Feedback](#scripts-de-feedback)
- [Scripts de ConfiguraÃ§Ã£o](#scripts-de-configuraÃ§Ã£o)
- [Scripts EspecÃ­ficos](#scripts-especÃ­ficos)
- [Como Executar](#como-executar)

## ðŸš€ Scripts BÃ¡sicos

### `test_simple.py`
**DescriÃ§Ã£o:** Teste bÃ¡sico para verificar se o backend estÃ¡ funcionando e enviar alguns logs simples.

**Funcionalidades:**
- Verifica se o backend estÃ¡ rodando
- Envia logs bÃ¡sicos para a API
- Testa endpoints fundamentais

**Uso:**
```bash
python test_simple.py
```

### `quick_test.py`
**DescriÃ§Ã£o:** Teste rÃ¡pido para verificar funcionalidades bÃ¡sicas do sistema.

**Funcionalidades:**
- Teste de conectividade
- Envio de logs de teste
- VerificaÃ§Ã£o de endpoints

**Uso:**
```bash
python quick_test.py
```

## ðŸ¤– Scripts de Machine Learning

### `test_ml.py`
**DescriÃ§Ã£o:** Teste completo do sistema de Machine Learning com dados realistas.

**Funcionalidades:**
- Gera logs com padrÃµes normais e anÃ´malos
- Treina modelos de ML
- Detecta anomalias
- Mostra estatÃ­sticas de detecÃ§Ã£o

**Uso:**
```bash
python test_ml.py
```

### `test_ml_simple.py`
**DescriÃ§Ã£o:** VersÃ£o simplificada do teste de ML para testes rÃ¡pidos.

**Funcionalidades:**
- Teste bÃ¡sico de treinamento e detecÃ§Ã£o
- Menos dados, execuÃ§Ã£o mais rÃ¡pida

**Uso:**
```bash
python test_ml_simple.py
```

### `test_ml_detailed.py`
**DescriÃ§Ã£o:** Teste detalhado que mostra informaÃ§Ãµes completas sobre as anomalias detectadas.

**Funcionalidades:**
- Exibe detalhes completos de cada anomalia
- Mostra scores de diferentes modelos
- Compara resultados entre algoritmos

**Uso:**
```bash
python test_ml_detailed.py
```

### `test_realistic.py`
**DescriÃ§Ã£o:** Gera dados mais realistas com menor proporÃ§Ã£o de anomalias.

**Funcionalidades:**
- Simula cenÃ¡rios mais prÃ³ximos da realidade
- ProporÃ§Ã£o controlada de anomalias
- PadrÃµes de trÃ¡fego realistas

**Uso:**
```bash
python test_realistic.py
```

### `test_network_anomaly.py`
**DescriÃ§Ã£o:** Teste especÃ­fico para detecÃ§Ã£o de anomalias de rede.

**Funcionalidades:**
- Gera logs com IPs em faixas especÃ­ficas
- Testa detecÃ§Ã£o de anomalias baseadas em IP
- Avalia precisÃ£o do sistema

**Uso:**
```bash
python test_network_anomaly.py
```

## ðŸ·ï¸ Scripts de Feedback

### `test_feedback.py`
**DescriÃ§Ã£o:** Teste bÃ¡sico do sistema de feedback.

**Funcionalidades:**
- Marca falsos positivos
- Marca verdadeiros positivos
- Testa endpoints de feedback

**Uso:**
```bash
python test_feedback.py
```

### `test_feedback_interface.py`
**DescriÃ§Ã£o:** Teste da interface de feedback.

**Funcionalidades:**
- Simula interaÃ§Ãµes com a interface web
- Testa funcionalidades de feedback via frontend

**Uso:**
```bash
python test_feedback_interface.py
```

### `test_feedback_fix.py`
**DescriÃ§Ã£o:** Teste para corrigir problemas especÃ­ficos do sistema de feedback.

**Funcionalidades:**
- Corrige erros de serializaÃ§Ã£o
- Testa campos especÃ­ficos do feedback

**Uso:**
```bash
python test_feedback_fix.py
```

### `test_feedback_filter.py`
**DescriÃ§Ã£o:** Testa o filtro de logs jÃ¡ marcados com feedback.

**Funcionalidades:**
- Verifica se logs com feedback sÃ£o filtrados
- Testa a funcionalidade de nÃ£o mostrar anomalias jÃ¡ marcadas

**Uso:**
```bash
python test_feedback_filter.py
```

### `test_retrain_effectiveness.py`
**DescriÃ§Ã£o:** Testa a eficÃ¡cia do retreinamento com feedback.

**Funcionalidades:**
- Compara performance antes e depois do retreinamento
- Avalia reduÃ§Ã£o de falsos positivos
- Mede melhoria na precisÃ£o

**Uso:**
```bash
python test_retrain_effectiveness.py
```

### `test_retrain_effectiveness_v2.py`
**DescriÃ§Ã£o:** VersÃ£o melhorada do teste de eficÃ¡cia de retreinamento.

**Funcionalidades:**
- Teste mais robusto e detalhado
- MÃ©tricas mais precisas
- Melhor anÃ¡lise de resultados

**Uso:**
```bash
python test_retrain_effectiveness_v2.py
```

### `test_retrain_effectiveness_v3.py`
**DescriÃ§Ã£o:** VersÃ£o final e otimizada do teste de retreinamento.

**Funcionalidades:**
- Teste completo e otimizado
- AnÃ¡lise estatÃ­stica detalhada
- RelatÃ³rios de performance

**Uso:**
```bash
python test_retrain_effectiveness_v3.py
```

## âš™ï¸ Scripts de ConfiguraÃ§Ã£o

### `test_config.py`
**DescriÃ§Ã£o:** Teste bÃ¡sico do sistema de configuraÃ§Ãµes.

**Funcionalidades:**
- Testa leitura de configuraÃ§Ãµes
- Testa atualizaÃ§Ã£o de parÃ¢metros
- Verifica persistÃªncia de configuraÃ§Ãµes

**Uso:**
```bash
python test_config.py
```

### `test_config_complete.py`
**DescriÃ§Ã£o:** Teste completo do sistema de configuraÃ§Ãµes.

**Funcionalidades:**
- Testa todas as funcionalidades de configuraÃ§Ã£o
- Valida diferentes tipos de parÃ¢metros
- Testa restauraÃ§Ã£o de padrÃµes

**Uso:**
```bash
python test_config_complete.py
```

## ðŸŽ¯ Scripts EspecÃ­ficos

### `test_anomalies.py`
**DescriÃ§Ã£o:** Teste especÃ­fico para detecÃ§Ã£o de anomalias.

**Funcionalidades:**
- Foca apenas na detecÃ§Ã£o
- AnÃ¡lise detalhada de anomalias
- ComparaÃ§Ã£o de algoritmos

**Uso:**
```bash
python test_anomalies.py
```

### `test_model_storage.py`
**DescriÃ§Ã£o:** Testa o armazenamento e carregamento de modelos.

**Funcionalidades:**
- Verifica persistÃªncia de modelos
- Testa carregamento de modelos salvos
- Valida integridade dos dados

**Uso:**
```bash
python test_model_storage.py
```

### `test_anomaly_description.py`
**DescriÃ§Ã£o:** Teste para verificar se as descriÃ§Ãµes de anomalias estÃ£o sendo geradas corretamente.

**Funcionalidades:**
- Verifica se as descriÃ§Ãµes explicativas das anomalias sÃ£o geradas
- Testa diferentes tipos de anomalias (horÃ¡rio, erro, admin, etc.)
- Avalia a qualidade das descriÃ§Ãµes geradas

**Uso:**
```bash
python test_anomaly_description.py
```

### `test_ip_changes.py`
**DescriÃ§Ã£o:** Teste especÃ­fico para verificar a detecÃ§Ã£o de mudanÃ§as de IP nas descriÃ§Ãµes de anomalias.

**Funcionalidades:**
- Testa detecÃ§Ã£o de mudanÃ§as de IP privado para pÃºblico
- Verifica mÃºltiplos IPs usados pelo mesmo cliente
- Analisa novos IPs nunca vistos antes
- Avalia mudanÃ§as frequentes de IP em pouco tempo

**CenÃ¡rios testados:**
- Cliente que muda de IP privado (192.168.1.100) para pÃºblico (203.45.67.89)
- Cliente que usa mÃºltiplos IPs em sequÃªncia rÃ¡pida
- Cliente que aparece com IP completamente novo
- Cliente normal como controle

**Uso:**
```bash
python test_ip_changes.py
```

### `test_true_positives.py`
**DescriÃ§Ã£o:** Teste especÃ­fico para verdadeiros positivos.

**Funcionalidades:**
- Gera cenÃ¡rios com anomalias conhecidas
- Avalia taxa de detecÃ§Ã£o de verdadeiros positivos
- Mede precisÃ£o do sistema

**Uso:**
```bash
python test_true_positives.py
```

### `test_false_positive_filter.py`
**DescriÃ§Ã£o:** Testa o filtro de falsos positivos.

**Funcionalidades:**
- Verifica se falsos positivos sÃ£o filtrados corretamente
- Testa a lÃ³gica de filtragem
- Avalia performance do filtro

**Uso:**
```bash
python test_false_positive_filter.py
```

## ðŸš€ Como Executar

### PrÃ©-requisitos

1. **Backend rodando:**
   ```bash
   python main.py
   ```

2. **DependÃªncias instaladas:**
   ```bash
   pip install -r requirements.txt
   ```

3. **MongoDB configurado:**
   - Certifique-se de que o MongoDB estÃ¡ rodando
   - Verifique as configuraÃ§Ãµes de conexÃ£o

### ExecuÃ§Ã£o BÃ¡sica

**âš ï¸ IMPORTANTE:** Use o terminal WSL para executar os testes, pois o Python do Windows pode nÃ£o funcionar corretamente.

1. **Navegue para a pasta de testes:**
   ```bash
   cd tests
   ```

2. **Execute um teste especÃ­fico:**
   ```bash
   wsl python3 nome_do_teste.py
   ```

3. **Execute todos os testes bÃ¡sicos:**
   ```bash
   wsl python3 test_simple.py
   wsl python3 test_ml.py
   wsl python3 test_feedback.py
   ```

### ExecuÃ§Ã£o no WSL (Recomendado)

Para executar os testes no ambiente WSL:

```bash
# No terminal WSL
cd /c/Users/mathe/workspace/api-log-analyzer/tests
python3 test_ml.py
```

### ExecuÃ§Ã£o Alternativa (se WSL nÃ£o estiver disponÃ­vel)

Se vocÃª nÃ£o puder usar o WSL, execute os testes a partir do diretÃ³rio raiz:

```bash
# No diretÃ³rio raiz do projeto
python tests/test_ml.py
```

### InterpretaÃ§Ã£o dos Resultados

- **âœ… Sucesso:** Teste executado sem erros
- **âŒ Erro:** Verifique logs e configuraÃ§Ãµes
- **âš ï¸ Aviso:** Problemas menores que nÃ£o impedem execuÃ§Ã£o

### Logs e Debug

Para ver logs detalhados, execute com verbose:

```bash
wsl python3 -u test_ml.py 2>&1 | tee test_output.log
```

## ðŸ“Š MÃ©tricas de Teste

### Performance Esperada

- **Taxa de DetecÃ§Ã£o:** > 90% para anomalias reais
- **Falsos Positivos:** < 10% em cenÃ¡rios normais
- **Tempo de ExecuÃ§Ã£o:** < 30 segundos para testes bÃ¡sicos

### ConfiguraÃ§Ãµes Recomendadas

- **Threshold:** 0.12 (padrÃ£o)
- **Horas para trÃ¡s:** 24 (padrÃ£o)
- **MÃ­nimo de logs:** 100 para treinamento

## ðŸ”§ Troubleshooting

### Problemas Comuns

1. **Backend nÃ£o responde:**
   - Verifique se `main.py` estÃ¡ rodando
   - Confirme porta 8000 estÃ¡ livre

2. **Erro de conexÃ£o MongoDB:**
   - Verifique se MongoDB estÃ¡ rodando
   - Confirme configuraÃ§Ãµes de conexÃ£o

3. **Erro de importaÃ§Ã£o:**
   - Instale dependÃªncias: `pip install -r requirements.txt`
   - Verifique versÃµes das bibliotecas

### Logs de Debug

Para habilitar logs detalhados, adicione no inÃ­cio dos scripts:

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

## ðŸ“ Contribuindo

Para adicionar novos testes:

1. Crie o arquivo na pasta `tests/`
2. Use o padrÃ£o de nomenclatura `test_*.py`
3. Adicione documentaÃ§Ã£o no README
4. Teste em diferentes cenÃ¡rios

## ðŸ“ž Suporte

Para problemas com os testes:

1. Verifique os logs de erro
2. Confirme configuraÃ§Ãµes do sistema
3. Teste com dados menores primeiro
4. Consulte a documentaÃ§Ã£o principal

---

**Ãšltima atualizaÃ§Ã£o:** Dezembro 2024  
**VersÃ£o:** 1.0.0

# ðŸ“Š Testes do API Log Analyzer

Este diretÃ³rio contÃ©m scripts de teste para validar as funcionalidades do sistema de detecÃ§Ã£o de anomalias.

## ðŸ§ª Scripts de Teste

### 1. `test_network_anomaly.py`
**Objetivo:** Testa detecÃ§Ã£o de anomalias baseadas em padrÃµes de rede
- Gera 10.000 logs normais de uma faixa de IP especÃ­fica
- Gera 100 logs anÃ´malos de outra faixa de IP
- Testa diferentes thresholds de detecÃ§Ã£o
- Valida reduÃ§Ã£o de falsos positivos

**Uso:**
```bash
python tests/test_network_anomaly.py
```

**MÃ©tricas Esperadas:**
- PrecisÃ£o: >95%
- Falsos positivos: <5%
- Verdadeiros positivos: >90%

### 2. `test_timeline.py`
**Objetivo:** Testa a funcionalidade de timeline temporal de anomalias
- Gera dados de teste com padrÃµes temporais especÃ­ficos
- Testa agrupamento por diferentes intervalos (15min, 30min, 1h)
- Valida geraÃ§Ã£o de dados para grÃ¡ficos
- Testa exportaÃ§Ã£o de dados temporais

**Uso:**
```bash
python tests/test_timeline.py
```

**Funcionalidades Testadas:**
- Endpoint `/ml/anomalies-timeline`
- Agrupamento temporal de anomalias
- GeraÃ§Ã£o de dados para Chart.js
- ExportaÃ§Ã£o de dados JSON
- Diferentes modelos ML (iforest, lof)

**MÃ©tricas Esperadas:**
- Dados temporais gerados corretamente
- GrÃ¡ficos com mÃºltiplos datasets
- ExportaÃ§Ã£o funcional
- Performance adequada

### 3. `test_ip_changes.py`
**Objetivo:** Testa detecÃ§Ã£o de mudanÃ§as de endereÃ§os IP
- Simula clientes acessando de mÃºltiplos IPs
- Testa detecÃ§Ã£o de comportamento suspeito
- Valida descriÃ§Ãµes de anomalias

**Uso:**
```bash
python tests/test_ip_changes.py
```

### 4. `test_config.py`
**Objetivo:** Testa o sistema de configuraÃ§Ãµes
- Valida leitura/escrita de configuraÃ§Ãµes
- Testa diferentes seÃ§Ãµes (ml_detection, feedback, etc.)
- Verifica persistÃªncia de configuraÃ§Ãµes

**Uso:**
```bash
python tests/test_config.py
```

### 5. `test_config_complete.py`
**Objetivo:** Teste completo do sistema de configuraÃ§Ãµes
- Testa todas as funcionalidades de configuraÃ§Ã£o
- Valida integraÃ§Ã£o com detecÃ§Ã£o ML
- Testa reset e histÃ³rico

**Uso:**
```bash
python tests/test_config_complete.py
```

### 6. `test_retrain_effectiveness.py`
**Objetivo:** Testa eficÃ¡cia do retreinamento com feedback
- Simula feedback de falsos positivos
- Valida melhoria na precisÃ£o apÃ³s retreinamento
- Testa reduÃ§Ã£o de falsos positivos

**Uso:**
```bash
python tests/test_retrain_effectiveness.py
```

### 7. `test_ml_detailed.py`
**Objetivo:** Teste detalhado de detecÃ§Ã£o ML
- Testa todos os modelos disponÃ­veis
- Compara performance entre modelos
- Valida scores de anomalia

**Uso:**
```bash
python tests/test_ml_detailed.py
```

### 8. `test_feedback.py`
**Objetivo:** Testa sistema de feedback
- Testa marcaÃ§Ã£o de falsos/verdadeiros positivos
- Valida armazenamento de feedback
- Testa histÃ³rico e estatÃ­sticas

**Uso:**
```bash
python tests/test_feedback.py
```

## ðŸš€ Como Executar os Testes

### PrÃ©-requisitos
1. Backend rodando: `python main.py`
2. DependÃªncias instaladas: `pip install -r requirements.txt`

### ExecuÃ§Ã£o Individual
```bash
# Executar teste especÃ­fico
python tests/test_timeline.py

# Executar com output detalhado
python -u tests/test_timeline.py
```

### ExecuÃ§Ã£o em Lote
```bash
# Executar todos os testes
python tests/test_all_scripts.py
```

## ðŸ“Š InterpretaÃ§Ã£o dos Resultados

### MÃ©tricas de Performance
- **PrecisÃ£o:** Porcentagem de detecÃ§Ãµes corretas
- **Falsos Positivos:** Anomalias detectadas incorretamente
- **Verdadeiros Positivos:** Anomalias reais detectadas
- **Tempo de Processamento:** Performance do sistema

### Indicadores de Sucesso
- âœ… PrecisÃ£o > 90%
- âœ… Falsos positivos < 10%
- âœ… Tempo de resposta < 5s
- âœ… Dados exportados corretamente

### Troubleshooting

#### Erro de ConexÃ£o
```
âŒ Erro ao conectar com o backend
```
**SoluÃ§Ã£o:** Verifique se o backend estÃ¡ rodando em `http://localhost:8000`

#### Erro de Modelo NÃ£o Encontrado
```
âŒ Modelo iforest nÃ£o encontrado
```
**SoluÃ§Ã£o:** Execute o treinamento primeiro ou use outro modelo

#### Erro de Dados Insuficientes
```
âŒ Nenhum log encontrado
```
**SoluÃ§Ã£o:** Gere mais dados de teste ou ajuste o perÃ­odo

#### Performance Lenta
```
â³ Processamento demorado
```
**SoluÃ§Ã£o:** 
- Reduza o nÃºmero de logs de teste
- Ajuste o perÃ­odo de anÃ¡lise
- Verifique recursos do sistema

## ðŸ”§ ConfiguraÃ§Ã£o de Testes

### VariÃ¡veis de Ambiente
```bash
export API_BASE="http://localhost:8000"
export TEST_API_ID="api_test"
export TEST_HOURS_BACK=24
```

### ParÃ¢metros de Teste
- **API_ID:** Identificador da API para teste
- **Hours_Back:** PerÃ­odo de anÃ¡lise em horas
- **Model_Name:** Modelo ML a ser testado
- **Threshold:** Sensibilidade da detecÃ§Ã£o

## ðŸ“ˆ Melhorias ContÃ­nuas

### Novos Testes
Para adicionar novos testes:
1. Crie script seguindo o padrÃ£o `test_*.py`
2. Implemente funÃ§Ã£o `main()` com validaÃ§Ãµes
3. Adicione documentaÃ§Ã£o no README
4. Inclua no `test_all_scripts.py`

### PadrÃµes de Teste
- Use nomes descritivos para logs de teste
- Implemente validaÃ§Ã£o de resultados
- Inclua mÃ©tricas de performance
- Documente casos de erro

### IntegraÃ§Ã£o
- Testes sÃ£o executados automaticamente
- Resultados sÃ£o logados para anÃ¡lise
- Falhas sÃ£o reportadas com contexto
- Performance Ã© monitorada continuamente 